import os
import requests
from bs4 import BeautifulSoup
from supabase import create_client

# K·∫øt n·ªëi Supabase
url = os.environ.get("SUPABASE_URL")
key = os.environ.get("SUPABASE_SERVICE_ROLE_KEY")
supabase = create_client(url, key)

def clean_price(price_val):
    try:
        if not price_val: return 0.0
        # Ch·ªâ gi·ªØ l·∫°i c√°c con s·ªë
        clean_str = "".join(filter(str.isdigit, str(price_val)))
        return float(clean_str) if clean_str else 0.0
    except:
        return 0.0

def save_gold(source_code, gold_type, buy, sell, web_url):
    data = {
        "source_code": source_code,
        "gold_type": gold_type,
        "buy_price": buy,
        "sell_price": sell,
        "source_url": web_url,
        "updated_at": "now()"
    }
    try:
        # S·ª≠ d·ª•ng on_conflict ƒë·ªÉ ghi ƒë√® d·ªØ li·ªáu c≈©, tr√°nh l·ªói Duplicate Key
        supabase.table("gold_prices").upsert(data, on_conflict="source_code,gold_type").execute()
        print(f"‚úÖ [{source_code}] {gold_type}: {buy} - {sell}")
    except Exception as e:
        print(f"‚ùå L·ªói l∆∞u {source_code}: {e}")

# H√†m d√πng chung ƒë·ªÉ c√†o t·ª´ WebGia
def crawl_from_webgia(source_code, target_url):
    print(f"üöÄ ƒêang c√†o {source_code} t·ª´ WebGia...")
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        res = requests.get(target_url, headers=headers, timeout=20)
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # T√¨m b·∫£ng gi√°
        table = soup.find('table', class_='table-price')
        if not table:
            # N·∫øu kh√¥ng th·∫•y class table-price, th·ª≠ t√¨m b·∫£ng b·∫•t k·ª≥
            table = soup.find('table')
            
        rows = table.find_all('tr')
        count = 0
        for row in rows:
            cols = row.find_all('td')
            if len(cols) >= 3:
                name = cols[0].get_text(strip=True)
                # Ch·ªâ l·∫•y c√°c lo·∫°i v√†ng ch√≠nh (SJC, Nh·∫´n, R·ªìng ThƒÉng Long...)
                if any(x in name.upper() for x in ["SJC", "NH·∫™N", "R·ªíNG THƒÇNG LONG", "DOJI", "PNJ"]):
                    buy = clean_price(cols[1].get_text(strip=True))
                    sell = clean_price(cols[2].get_text(strip=True))
                    if buy > 100000:
                        save_gold(source_code, name, buy, sell, target_url)
                        count += 1
        if count == 0: print(f"‚ö†Ô∏è {source_code}: Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu.")
    except Exception as e:
        print(f"‚ùå L·ªói {source_code}: {e}")

# 1. B·∫¢O T√çN M·∫†NH H·∫¢I (V·∫´n c√†o tr·ª±c ti·∫øp v√¨ web n√†y r·∫•t nhanh v√† d·ªÖ)
def crawl_btmh():
    print("üöÄ ƒêang c√†o B·∫£o T√≠n M·∫°nh H·∫£i...")
    target_url = "https://baotinmanhhai.vn/gia-vang-hom-nay"
    try:
        res = requests.get(target_url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=20)
        soup = BeautifulSoup(res.text, 'html.parser')
        rows = soup.select('table tr')
        for row in rows:
            cols = row.find_all('td')
            if len(cols) >= 3:
                name = cols[0].get_text(strip=True)
                if any(x in name for x in ["SJC", "Kim Gia B·∫£o", "Nh·∫´n Tr√≤n"]):
                    save_gold("BTMH", name, clean_price(cols[1].text), clean_price(cols[2].text), target_url)
    except: print("L·ªói BTMH")

# 2. PH√ö QU√ù (V·∫´n c√†o tr·ª±c ti·∫øp ƒë∆∞·ª£c)
def crawl_phuquy():
    print("üöÄ ƒêang c√†o Ph√∫ Qu√Ω...")
    target_url = "https://phuquygroup.vn/"
    try:
        res = requests.get(target_url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=20)
        soup = BeautifulSoup(res.text, 'html.parser')
        rows = soup.select('table tr')
        for row in rows:
            cols = row.find_all('td')
            if len(cols) >= 3:
                name = cols[0].get_text(strip=True)
                if any(x in name for x in ["SJC", "Ph√∫ Qu√Ω"]):
                    save_gold("PHUQUY", name, clean_price(cols[1].text), clean_price(cols[2].text), target_url)
    except: print("L·ªói Ph√∫ Qu√Ω")

if __name__ == "__main__":
    # C√†o DOJI t·ª´ WebGia
    crawl_from_webgia("DOJI", "https://webgia.com/gia-vang/doji/")
    
    # C√†o B·∫£o T√≠n Minh Ch√¢u t·ª´ WebGia
    crawl_from_webgia("BTMC", "https://webgia.com/gia-vang/bao-tin-minh-chau/")
    
    # C√†o 2 ngu·ªìn c√≤n l·∫°i tr·ª±c ti·∫øp
    crawl_btmh()
    crawl_phuquy()
